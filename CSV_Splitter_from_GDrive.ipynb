{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marioabduh/portfolio/blob/main/CSV_Splitter_from_GDrive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Google Colab for the first run"
      ],
      "metadata": {
        "id": "smOYVnjOyoMG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVJ95cDU-6D0"
      },
      "outputs": [],
      "source": [
        "# Install necessary modules\n",
        "\n",
        "!pip install kora\n",
        "from kora.xattr import get_id\n",
        "\n",
        "!pip install -U -q PyDrive2\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "gdrive = GoogleDrive(gauth)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "# Imports necessary nmodules\n",
        "import pandas as pd\n",
        "import random\n",
        "import string\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "print('Setup Complete!')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Specify Google Drive folder location and get folderID"
      ],
      "metadata": {
        "id": "i1EjKIkDyMDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the big files folder path in your Google Drive\n",
        "big_files_folder = '/content/drive/My Drive/Portfolio/Big Files'\n",
        "file_list = os.listdir(big_files_folder)\n",
        "for file_name in file_list:\n",
        "    try:\n",
        "        file_path = os.path.join(big_files_folder, file_name)\n",
        "        os.remove(file_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Error deleting {file_name}: {e}\")\n",
        "\n",
        "# Get folderID for big files folder\n",
        "folder_id = get_id(big_files_folder)\n",
        "\n",
        "\n",
        "# Specify the small files folder path in your Google Drive\n",
        "small_files_folder = '/content/drive/My Drive/Portfolio/Small Files'\n",
        "file_list = os.listdir(small_files_folder)\n",
        "for file_name in file_list:\n",
        "    try:\n",
        "        file_path = os.path.join(small_files_folder, file_name)\n",
        "        os.remove(file_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Error deleting {file_name}: {e}\")"
      ],
      "metadata": {
        "id": "tOJ4NxdvyHEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a random char, save it as csv, and move it to a Big Files folder in Google Drive."
      ],
      "metadata": {
        "id": "nE-ZSaTSSTaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_random_string(length):\n",
        "    characters = string.ascii_letters + string.digits\n",
        "    return ''.join(random.choice(characters) for _ in range(length))\n",
        "\n",
        "num_lines = 1000000\n",
        "for i in range(2):\n",
        "  random_strings = [generate_random_string(10) for _ in range(num_lines)]\n",
        "\n",
        "  # Create a DataFrame with the random strings\n",
        "  df = pd.DataFrame({'RandomString': random_strings})\n",
        "\n",
        "  # Save the DataFrame to a CSV file\n",
        "  df.to_csv(f'random_strings-{i}.csv', index=False)\n",
        "\n",
        "  # Specify the source path (where the CSV file is currently)\n",
        "  source_path = f'random_strings-{i}.csv'\n",
        "\n",
        "  # Move the file\n",
        "  shutil.move(source_path, big_files_folder)"
      ],
      "metadata": {
        "id": "X7JI4JEvSWlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get CSV files from a folder and join it in 1 csv files"
      ],
      "metadata": {
        "id": "niZ61z0VUOQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import and merge csv content from drive folder to pandas\n",
        "query = f\"'{folder_id}' in parents and trashed=false and fileExtension='csv'\"\n",
        "list_df = gdrive.ListFile({'q': query}).GetList()\n",
        "list_file_dr = []\n",
        "list_title_df = []\n",
        "for file_df in list_df:\n",
        "    list_file_dr.append(file_df['id'])\n",
        "    list_title_df.append(file_df['title'])\n",
        "\n",
        "df_df = pd.DataFrame()\n",
        "\n",
        "for id, title in zip(list_file_dr, list_title_df):\n",
        "    each_file_df = gdrive.CreateFile({'id': id})\n",
        "    each_file_df.GetContentFile(title)\n",
        "    df_each_file_df = pd.read_csv(title)\n",
        "    print(title, len(df_each_file_df))\n",
        "    # df_df = df_df.append(df_each_file_df, ignore_index=True)\n",
        "    df_df = pd.concat([df_df,df_each_file_df], ignore_index = True)\n",
        "\n",
        "\n",
        "df_df.info()\n",
        "df_df.head()"
      ],
      "metadata": {
        "id": "t5VrJOWxVSGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split the csv file into smaller file containing custom row length"
      ],
      "metadata": {
        "id": "nf6m2Bn4WKOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_size = 100000\n",
        "list_df_df = [df_df[i:i+chunk_size] for i in range(0,len(df_df),chunk_size)]\n",
        "for i, chunk in enumerate(list_df_df):\n",
        "    chunk.to_csv(f'/content/drive/My Drive/Portfolio/Small Files/file_{i}.csv', header=None, index=None)"
      ],
      "metadata": {
        "id": "BC9A9KZyWSOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "eV8eOICN4hzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbyHPhs2vK0-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}